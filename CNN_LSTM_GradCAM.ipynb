{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8253ea",
   "metadata": {},
   "source": [
    "# CNN-LSTM with Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be250be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\n",
    "                                     TimeDistributed, LSTM)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79a601-2cf6-4e54-9be5-8c6738cb9b69",
   "metadata": {},
   "source": [
    "## Preprocess videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a68ef026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline (extract 10 frames per video)\n",
    "def extract_frames(video_path, num_frames=10, size=(100, 100)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = max(total_frames // num_frames, 1)\n",
    "    for i in range(0, total_frames, step):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, size)\n",
    "            frame = frame / 255.0\n",
    "            frames.append(frame)\n",
    "        if len(frames) == num_frames:\n",
    "            break\n",
    "    cap.release()\n",
    "    return np.array(frames) if len(frames) == num_frames else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49e2726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from directory structure: dataset/ClassName/*.mp4\n",
    "def load_dataset(data_dir):\n",
    "    X, y = [], []\n",
    "    class_map = {}\n",
    "    for idx, class_name in enumerate(sorted(os.listdir(data_dir))):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        class_map[idx] = class_name\n",
    "        for video_file in tqdm(os.listdir(class_path), desc=f\"{class_name}\"):\n",
    "            video_path = os.path.join(class_path, video_file)\n",
    "            frames = extract_frames(video_path)\n",
    "            if frames is not None:\n",
    "                X.append(frames)\n",
    "                y.append(idx)\n",
    "    return np.array(X), to_categorical(y), class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495da92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, class_map = load_dataset('../CKT Dataset')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962c3d5-fb34-4fa0-9fba-22c3de4388be",
   "metadata": {},
   "source": [
    "## Define and train CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59b96ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN-LSTM model\n",
    "model = Sequential([\n",
    "    Input(shape=(10, 100, 100, 3)),  # explicitly define input shape here\n",
    "    TimeDistributed(Conv2D(16, (3, 3), strides=(2, 2), padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((4, 4), strides=(2, 2), padding='same')),\n",
    "    TimeDistributed(Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((4, 4), strides=(2, 2), padding='same')),\n",
    "    TimeDistributed(Conv2D(64, (3, 3), strides=(2, 2), padding='same', activation='relu'), name='target_layer'),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2), padding='same')),\n",
    "    TimeDistributed(Conv2D(128, (3, 3), strides=(2, 2), padding='same', activation='relu')),\n",
    "    TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2), padding='same')),\n",
    "    TimeDistributed(Flatten()),\n",
    "    LSTM(128),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac45b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train CNN\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=16, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9983ab-a8be-4dc9-ba03-6fb458067894",
   "metadata": {},
   "source": [
    "## Grad-CAM implementation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1cd9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more details, check out: https://keras.io/examples/vision/grad_cam/\n",
    "# Grad-CAM\n",
    "def make_gradcam_heatmap(sequential_model, video, class_index, frame_index):\n",
    "    # Recreate the functional version of the Sequential model\n",
    "    input_layer = Input(shape=(10, 100, 100, 3))\n",
    "    x = input_layer\n",
    "    for layer in sequential_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name == \"target_layer\":\n",
    "            target_output = x\n",
    "    output_layer = x\n",
    "\n",
    "    grad_model = Model(inputs=input_layer, outputs=[target_output, output_layer])\n",
    "\n",
    "    # Forward pass\n",
    "    input_tensor = tf.convert_to_tensor(video[np.newaxis])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(input_tensor)\n",
    "        loss = predictions[:, class_index]\n",
    "\n",
    "    # Backpropagation\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_output = conv_outputs[0][frame_index]\n",
    "    heatmap = conv_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc72a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Grad-CAM\n",
    "video = X_val[10]\n",
    "predicted_class = np.argmax(model.predict(video[np.newaxis]), axis=1)[0]\n",
    "heatmap = make_gradcam_heatmap(model, video, predicted_class, frame_index=0)\n",
    "original_frame = video[0]\n",
    "heatmap_resized = cv2.resize(heatmap, (100, 100))\n",
    "overlay = cm.jet(heatmap_resized)[..., :3]\n",
    "superimposed = (overlay * 0.4 + original_frame).clip(0, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 3, 1); plt.title(\"Original\"); plt.imshow(original_frame); plt.axis('off')\n",
    "plt.subplot(1, 3, 2); plt.title(\"Heatmap\"); plt.imshow(heatmap_resized, cmap='jet'); plt.axis('off')\n",
    "plt.subplot(1, 3, 3); plt.title(\"Overlay\"); plt.imshow(superimposed); plt.axis('off')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e719449-eb2c-46a6-96a1-c7c83f0695f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Grad-CAM for all frames in video\n",
    "video = X_val[70]  # shape: (10, 100, 100, 3)\n",
    "predicted_class = np.argmax(model.predict(video[np.newaxis]), axis=1)[0]\n",
    "\n",
    "# Generate heatmaps for each frame\n",
    "heatmaps = []\n",
    "for i in range(10):\n",
    "    heatmap = make_gradcam_heatmap(model, video, predicted_class, frame_index=i)\n",
    "    heatmaps.append(heatmap)\n",
    "\n",
    "fig, axs = plt.subplots(10, 3, figsize=(12, 20))\n",
    "for i in range(10):\n",
    "    original_frame = video[i]\n",
    "    heatmap_resized = cv2.resize(heatmaps[i], (100, 100))\n",
    "    overlay = cm.jet(heatmap_resized)[..., :3]\n",
    "    superimposed = (overlay * 0.4 + original_frame).clip(0, 1)\n",
    "\n",
    "    axs[i, 0].imshow(original_frame)\n",
    "    axs[i, 0].axis('off')\n",
    "    axs[i, 0].set_title(f\"Frame {i}\")\n",
    "\n",
    "    axs[i, 1].imshow(heatmap_resized, cmap='jet')\n",
    "    axs[i, 1].axis('off')\n",
    "    axs[i, 1].set_title(f\"Heatmap {i}\")\n",
    "\n",
    "    axs[i, 2].imshow(superimposed)\n",
    "    axs[i, 2].axis('off')\n",
    "    axs[i, 2].set_title(f\"Superimposed {i}\")\n",
    "\n",
    "plt.suptitle(f\"Grad-CAM for Class: {predicted_class}\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97])  # Leave space for title\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
