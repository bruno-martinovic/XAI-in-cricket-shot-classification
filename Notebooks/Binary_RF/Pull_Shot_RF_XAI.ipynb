{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20367b59-af0f-44ce-9a29-b7d144cfb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyALE imblearn lime matplotlib numpy pandas seaborn shap scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34514ac7-5471-4f60-a36e-6469f008105e",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a374758-9747-4e22-8882-6d3242183454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701319bb-a868-4848-b4a7-aa5b876c44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original CSV file\n",
    "df = pd.read_csv(\"keypoints_per_frame.csv\")\n",
    "\n",
    "# Convert label: 'Bowled' â†’ 1, all others â†’ 0\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x == \"Pull Shot\" else 0)\n",
    "\n",
    "# Save the modified CSV (optional)\n",
    "df.to_csv(\"Keypoint datasets/pull_shot_keypoints_per_frame.csv\", index=False)\n",
    "\n",
    "# (Optional) preview the result\n",
    "df.head()\n",
    "\n",
    "#Prepare features and labels\n",
    "X = df.drop(columns=[\"label\", \"video\", \"frame\"])\n",
    "y = df[\"label\"]\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d6768-d351-4c59-a0be-e11f2b15cce6",
   "metadata": {},
   "source": [
    "# LOAD DATASET AND PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba844d-199c-4c2d-82d2-8855c23ae9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŸ¦ Step 4: Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82ab59a-9c29-4b8f-8baf-3da5af5db148",
   "metadata": {},
   "source": [
    "# RF TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844ccc4-22b6-4ca5-89f9-0c1caf8e8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RF\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "#Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53206405-58a3-493b-8e50-9a635d60f622",
   "metadata": {},
   "source": [
    "# FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c09950-b2a0-45f5-a92c-0863e3196754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = importances.argsort()[::-1]\n",
    "top_n = 51\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(12, 30))\n",
    "\n",
    "# Get top feature importances and names\n",
    "top_features = [X.columns[i] for i in indices[:top_n]]\n",
    "top_importances = importances[indices[:top_n]]\n",
    "\n",
    "# Plot\n",
    "ax = sns.barplot(x=top_importances, y=top_features)\n",
    "\n",
    "# Annotate each bar with the importance value\n",
    "for i, (value, name) in enumerate(zip(top_importances, top_features)):\n",
    "    ax.text(value + 0.001, i, f\"{value:.4f}\", va='center')\n",
    "\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345caf9-4554-47d0-87ff-0d71997f156a",
   "metadata": {},
   "source": [
    "# PERMUTATION IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec09c7-5a26-4d80-a17e-2be69b78156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# Show top 10 features\n",
    "sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "for i in sorted_idx[:10]:\n",
    "    print(f\"{X_test.columns[i]}: {result.importances_mean[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6956c47-5d05-4cfd-b2e9-42988ae826b9",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c9179-b708-4995-8247-9ba17ad46d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding SHAP to the RF classifier\n",
    "\n",
    "# Create the SHAP explainer for the Random Forest model\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(shap_values.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d9d93-1d4f-432c-8b3c-c132105b96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "# Generate a SHAP summary plot\n",
    "shap.summary_plot(shap_values[:,:,1], X_test)\n",
    "\n",
    "# Generate a SHAP force plot for an individual prediction\n",
    "shap.plots.force(explainer.expected_value[1], shap_values[5,:,1], X_test.iloc[5])\n",
    "\n",
    "#Generate Waterfall\n",
    "shap.plots.waterfall(\n",
    "    shap.Explanation(\n",
    "        values=shap_values[5, :, 1],\n",
    "        base_values=explainer.expected_value[1],\n",
    "        data=X_test.iloc[5],\n",
    "        feature_names=X_test.columns.tolist()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed854e-d0e5-4e0a-a69b-e7bd01c242aa",
   "metadata": {},
   "source": [
    "# TOP CONFIDENT PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6338c-a539-4f70-bca4-5f207ef251f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for class 1\n",
    "probs = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Get top N indices by prediction confidence\n",
    "N = 5\n",
    "top_indices = np.argsort(-np.abs(probs - 0.5))[:N]  # furthest from 0.5\n",
    "\n",
    "# Plot waterfall for each\n",
    "for idx in top_indices:\n",
    "    print(f\"Waterfall for test sample #{idx} (prob = {probs[idx]:.2f})\")\n",
    "    shap.plots.waterfall(\n",
    "        shap.Explanation(\n",
    "            values=shap_values[idx, :, 1],\n",
    "            base_values=explainer.expected_value[1],\n",
    "            data=X_test.iloc[idx],\n",
    "            feature_names=X_test.columns.tolist()\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e170a-96a6-4a0f-9ccb-b207321997ae",
   "metadata": {},
   "source": [
    "# TOP POSITIVE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ec189-356c-4315-b4d5-55cb9fb27bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities and labels\n",
    "probs = rf.predict_proba(X_test)[:, 1]       # Probability of class 1\n",
    "preds = rf.predict(X_test)                   # Predicted class labels\n",
    "\n",
    "# Keep only indices where the predicted class is 1\n",
    "class_1_indices = np.where(preds == 1)[0]\n",
    "\n",
    "# Compute confidence as distance from 0.5\n",
    "confidences = np.abs(probs[class_1_indices] - 0.5)\n",
    "\n",
    "# Get top N class 1 predictions by confidence\n",
    "N = 10\n",
    "top_indices = class_1_indices[np.argsort(-confidences)[:N]]\n",
    "\n",
    "# Plot SHAP waterfall for each\n",
    "for idx in top_indices:\n",
    "    print(f\"Waterfall for test sample #{idx} (prob = {probs[idx]:.2f})\")\n",
    "    shap.plots.waterfall(\n",
    "        shap.Explanation(\n",
    "            values=shap_values[idx, :, 1],  # Class 1 SHAP values\n",
    "            base_values=explainer.expected_value[1],\n",
    "            data=X_test.iloc[idx],\n",
    "            feature_names=X_test.columns.tolist()\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79273560-4904-4e87-9556-3696f18e3d28",
   "metadata": {},
   "source": [
    "# TOP NEGATIVE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf8f12-78c2-454a-9cf7-59df8325b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities and labels\n",
    "probs = rf.predict_proba(X_test)[:, 1]       # Probability of class 1\n",
    "preds = rf.predict(X_test)                   # Predicted class labels\n",
    "\n",
    "# Keep only indices where the predicted class is 1\n",
    "class_1_indices = np.where(preds == 0)[0]\n",
    "\n",
    "# Compute confidence as distance from 0.5\n",
    "confidences = np.abs(probs[class_1_indices] - 0.5)\n",
    "\n",
    "# Get top N class 1 predictions by confidence\n",
    "N = 10\n",
    "top_indices = class_1_indices[np.argsort(-confidences)[:N]]\n",
    "\n",
    "# Plot SHAP waterfall for each\n",
    "for idx in top_indices:\n",
    "    print(f\"Waterfall for test sample #{idx} (prob = {probs[idx]:.2f})\")\n",
    "    shap.plots.waterfall(\n",
    "        shap.Explanation(\n",
    "            values=shap_values[idx, :, 1],  # Class 1 SHAP values\n",
    "            base_values=explainer.expected_value[1],\n",
    "            data=X_test.iloc[idx],\n",
    "            feature_names=X_test.columns.tolist()\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ede69e-c7d0-44be-93d8-74248c80cb22",
   "metadata": {},
   "source": [
    "# MOST INFULENTIAL FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46c7cd3-84ad-4968-a2ea-9efd8b042d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get SHAP values for class 1\n",
    "shap_class1 = shap_values[:, :, 1]  # shape: (samples, features)\n",
    "\n",
    "# Step 2: Identify the most influential feature overall (e.g., by mean absolute SHAP value)\n",
    "mean_abs_shap = np.abs(shap_class1).mean(axis=0)\n",
    "top_feature_index = np.argmax(mean_abs_shap)\n",
    "top_feature_name = X_test.columns[top_feature_index]\n",
    "\n",
    "print(f\"Top contributing feature: {top_feature_name}\")\n",
    "\n",
    "# Step 3: Get the top 10 samples where that feature has the highest SHAP value\n",
    "top_10_indices = np.argsort(-np.abs(shap_class1[:, top_feature_index]))[:10]\n",
    "\n",
    "# Step 4: Display info for those samples\n",
    "for idx in top_10_indices:\n",
    "    prob = rf.predict_proba(X_test.iloc[[idx]])[0, 1]\n",
    "    shap_val = shap_class1[idx, top_feature_index]\n",
    "    print(f\"Sample #{idx} â€” Prob(class 1): {prob:.2f}, SHAP[{top_feature_name}] = {shap_val:.3f}\")\n",
    "    \n",
    "    shap.plots.waterfall(\n",
    "        shap.Explanation(\n",
    "            values=shap_class1[idx],\n",
    "            base_values=explainer.expected_value[1],\n",
    "            data=X_test.iloc[idx],\n",
    "            feature_names=X_test.columns.tolist()\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045fb268-d1cd-4bc5-b427-a2bcc04ec6d7",
   "metadata": {},
   "source": [
    "# GROUPED SHAP BY JOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e60de-0b9a-43b7-863e-79838f8b3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = defaultdict(list)\n",
    "for i, name in enumerate(X_test.columns):\n",
    "    group_key = name.rsplit(\"_\", 1)[0]  # splits from the right, keeping e.g. 'LeftEyeInner'\n",
    "    groups[group_key].append(i)\n",
    "# Dictionary looks like this, name-value pair\n",
    "# {\n",
    "#     'LeftElbow': [24, 25, 26],\n",
    "#     'RightShoulder': [18, 19, 20],\n",
    "#     ...\n",
    "# }\n",
    "# SHAP values for class 1\n",
    "shap_vals = shap_values[:, :, 1]  # shape: (n_samples, n_features)\n",
    "\n",
    "# Aggregate absolute SHAP values over groups\n",
    "group_shap_values = []\n",
    "group_names = []\n",
    "\n",
    "for group_name, indices in groups.items():\n",
    "    mean_abs_shap = np.abs(shap_vals[:, indices]).mean()\n",
    "    group_shap_values.append(mean_abs_shap)\n",
    "    group_names.append(group_name)\n",
    "\n",
    "# Sort by importance\n",
    "sorted_indices = np.argsort(group_shap_values)[::-1]\n",
    "group_names_sorted = [group_names[i] for i in sorted_indices]\n",
    "group_values_sorted = [group_shap_values[i] for i in sorted_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=group_values_sorted, y=group_names_sorted)\n",
    "plt.title(\"Grouped SHAP Feature Importance (Class 1)\")\n",
    "plt.xlabel(\"Mean |SHAP value|\")\n",
    "plt.ylabel(\"Keypoint\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada7510-9fb6-43af-afdf-a677e2cd48bd",
   "metadata": {},
   "source": [
    "# GROUPED SHAP BY LIMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ed3f8-6254-4923-b62f-b34b9637e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make mapping per limb\n",
    "limb_mapping = {\n",
    "    \"Head\": [\n",
    "        \"Nose\", \"LeftEyeInner\", \"LeftEye\", \"LeftEyeOuter\",\n",
    "        \"RightEyeInner\", \"RightEye\", \"RightEyeOuter\",\n",
    "        \"LeftEar\", \"RightEar\", \"MouthLeft\", \"MouthRight\"\n",
    "    ],\n",
    "    \"Left Arm\": [\"LeftShoulder\", \"LeftElbow\", \"LeftWrist\"],\n",
    "    \"Right Arm\": [\"RightShoulder\", \"RightElbow\", \"RightWrist\"]\n",
    "}\n",
    "\n",
    "# Build groups by limb\n",
    "limb_groups = defaultdict(list)\n",
    "\n",
    "for i, name in enumerate(X_test.columns):\n",
    "    keypoint = name.rsplit(\"_\", 1)[0]  # e.g., \"LeftElbow\"\n",
    "\n",
    "    for limb, keypoints in limb_mapping.items():\n",
    "        if keypoint in keypoints:\n",
    "            limb_groups[limb].append(i)\n",
    "            break\n",
    "\n",
    "shap_vals = shap_values[:, :, 1]  # class 1 SHAP values\n",
    "\n",
    "limb_names = []\n",
    "limb_shap_values = []\n",
    "\n",
    "# For each limb, get all shap values for class 1 by index\n",
    "for limb, indices in limb_groups.items():\n",
    "    mean_abs_shap = np.abs(shap_vals[:, indices]).mean()\n",
    "    limb_names.append(limb)\n",
    "    limb_shap_values.append(mean_abs_shap)\n",
    "\n",
    "# Sort by effect\n",
    "sorted_idx = np.argsort(limb_shap_values)[::-1]\n",
    "limb_names_sorted = [limb_names[i] for i in sorted_idx]\n",
    "limb_values_sorted = [limb_shap_values[i] for i in sorted_idx]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=limb_values_sorted, y=limb_names_sorted)\n",
    "plt.title(\"Grouped SHAP Importance by Limb (Class 1)\")\n",
    "plt.xlabel(\"Mean |SHAP value|\")\n",
    "plt.ylabel(\"Body Region\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f880f5-0950-4e65-8c66-ba161db79786",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65763bb6-ffe9-4236-932a-2b748da624f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# Step 1: Create the explainer\n",
    "limeExplainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_train.values,\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    class_names=[str(cls) for cls in rf.classes_],\n",
    "    mode='classification',\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "# Step 2: Define the wrapper predict function with column names\n",
    "def predict_fn_with_names(x):\n",
    "    # Convert x to DataFrame with feature names\n",
    "    df = pd.DataFrame(x, columns=X_train.columns)\n",
    "    return rf.predict_proba(df)\n",
    "\n",
    "# Step 3: Choose a test sample to explain (e.g., index 5)\n",
    "i = 285\n",
    "exp = limeExplainer.explain_instance(\n",
    "    data_row=X_test.iloc[i].values,         # values of the instance\n",
    "    predict_fn=predict_fn_with_names,       # your fixed function\n",
    "    num_features=10                         # number of top features to show\n",
    ")\n",
    "\n",
    "# Step 4: Show the explanation\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8075c5ac-ff16-4d0a-9c5b-49cf4aeaa12f",
   "metadata": {},
   "source": [
    "# ALE PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ecc6a-9ffb-4e4d-837e-b2722ba5622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca6ca7-b113-4d0a-833e-e2a61c3ac81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Class1Wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, X):\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(X, columns=X_test.columns)\n",
    "        return self.model.predict_proba(df)[:, 1]  # only class 1 probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64dd57b-d9b3-4dab-899e-1c613778003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyALE import ale\n",
    "\n",
    "\n",
    "wrapped_model = Class1Wrapper(rf)\n",
    "\n",
    "ale_eff = ale(\n",
    "    X=X_test,\n",
    "    model=wrapped_model,\n",
    "    feature=[\"LeftWrist_y\"],  # must be a list\n",
    "    include_CI=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2314c483-32ef-4b75-8d8f-505a9232c3e0",
   "metadata": {},
   "source": [
    "# SAVE IN CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e0d97-2cfd-42bc-a067-9d9fa48f2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract SHAP values for class 1\n",
    "# shap_class_1 = shap_values[:, :, 1]  # shape: (n_samples, n_features)\n",
    "\n",
    "# # Prepare the prediction info\n",
    "# prediction_info = pd.DataFrame({\n",
    "#     \"Sample\": range(len(X_test)),\n",
    "#     \"True Label\": y_test.values,\n",
    "#     \"Predicted Label\": y_pred,\n",
    "#     \"Prob Class 0\": y_proba[:, 0],\n",
    "#     \"Prob Class 1\": y_proba[:, 1]\n",
    "# })\n",
    "\n",
    "# # Extract SHAP values for class 1\n",
    "# shap_class_1 = shap_values[:, :, 1]  # shape: (n_samples, n_features)\n",
    "\n",
    "# # Create column names for SHAP values\n",
    "# shap_columns = [f\"shap_{name}\" for name in X_test.columns]\n",
    "\n",
    "# # Turn SHAP values into a DataFrame\n",
    "# shap_df = pd.DataFrame(shap_class_1, columns=shap_columns)\n",
    "\n",
    "# # Reset index for consistency\n",
    "# shap_df = shap_df.reset_index(drop=True)\n",
    "\n",
    "# # Final DataFrame with everything\n",
    "# full_results = pd.concat([prediction_info, X_test.reset_index(drop=True), shap_df], axis=1)\n",
    "\n",
    "# # Save to CSV\n",
    "# full_results.to_csv(\"Shap_result_tables/pull_shot_shap_predictions_rf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
